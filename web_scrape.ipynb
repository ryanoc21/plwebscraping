{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Premier League Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries \n",
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd \n",
    "import time "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping data for multiple seasons and multiple teams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years that we will require data for \n",
    "years = list(range(2023,2021,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list that will contain all dataframes after the loop is finished \n",
    "all_matches = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standings_url = \"https://fbref.com/en/comps/9/Premier-League-Stats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    # Get URL \n",
    "    data = requests.get(standings_url) \n",
    "\n",
    "    # Instantiate Soup Object \n",
    "    soup = BeautifulSoup(data.text) \n",
    "    \n",
    "   # Select the league standings stats table \n",
    "    standings_table = soup.select('#switcher_results2022-202391')[0]   \n",
    "\n",
    "    # Find all the anchor tags in the standings table \n",
    "    links = standings_table.find_all('a') \n",
    "\n",
    "    # Extract the href property from the links \n",
    "    # This will give all the links in the table associated with each squad, includes top scorer, goalkeeper etc\n",
    "    all_links = [l.get(\"href\") for l in links]\n",
    "\n",
    "    # Filter the links so you only get the squad stats links \n",
    "    squad_links = [l for l in all_links if '/squads/' in l]\n",
    "    \n",
    "    # Turn the above links into full urls \n",
    "    team_urls = [f\"https://fbref.com{l}\" for l in squad_links]\n",
    "\n",
    "    # Get the previous year data \n",
    "    previous_season = soup.select(\"a.prev\")[0].get(\"href\") \n",
    "    standings_url = f\"https://fbref.com/{previous_season}\"\n",
    "\n",
    "    # Loop through each of the team urls \n",
    "    for team_url in team_urls:\n",
    "        # Get the team name \n",
    "        team_name = team_url.split('/')[-1].replace(\"-Stats\",\"\").replace(\"-\",\"\") \n",
    "\n",
    "        # Get the team url \n",
    "        data = requests.get(team_url) \n",
    "\n",
    "        # Read html for scores and fixtures \n",
    "        matches = pd.read_html(data.text,match='Scores & Fixtures')\n",
    "        matches = matches[0]\n",
    "\n",
    "        # Read html for shooting \n",
    "        shoot_soup = BeautifulSoup(data.text)\n",
    "\n",
    "        links = shoot_soup.find_all('a') \n",
    "        links = [l.get('href') for l in links]\n",
    "\n",
    "        shooting_links = [l for l in links if l and 'all_comps/shooting/' in l] \n",
    "        shooting_links = shooting_links[0]\n",
    "        \n",
    "        shoot_data = requests.get(f\"https://fbref.com{shooting_links}\")\n",
    "        shoot_data = pd.read_html(shoot_data.text,match='Shooting')[0]\n",
    "        shoot_data.columns = shoot_data.columns.droplevel()\n",
    "\n",
    "        # Wrap shooting data in try and except to prevent errors from teams having on shooting data \n",
    "        try: \n",
    "            # Merge the data and shooting data together \n",
    "            # We are taking data from the shoot_data frame of date, shots, shots on target, distance of shots, frees, pens, pens attempted in order. \n",
    "            team_data = matches.merge(shoot_data[[\"Date\",\"Sh\",\"SoT\",\"Dist\",\"FK\",\"PK\",\"PKatt\"]],on='Date')\n",
    "                        \n",
    "        except ValueError: \n",
    "            continue \n",
    "\n",
    "        # Only get data for the premier league \n",
    "        team_data = team_data[team_data['Comp'] == 'Premier League']\n",
    "\n",
    "        # Add in team name and season columns \n",
    "        team_data['Team'] = team_name \n",
    "        team_data['Season'] = year \n",
    "        \n",
    "        # Append team_data to the all matches list \n",
    "        all_matches.append(team_data) \n",
    "\n",
    "        # Add sleep \n",
    "        time.sleep(10) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
